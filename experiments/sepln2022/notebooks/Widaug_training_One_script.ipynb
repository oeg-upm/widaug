{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN6nu8CrpA9b"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAgNSsdxn2gH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f50887-ac85-4a58-8f6f-4897b8528b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 451 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 82.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 77.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 91.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 82.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 65.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 240 kB 4.4 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets -q\n",
        "!pip install transformers -q\n",
        "!pip install seqeval -q\n",
        "#!pip install wandb -q\n",
        "!pip install emoji -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python"
      ],
      "metadata": {
        "id": "PK6tE3mr4duM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qjh1Y573W1G"
      },
      "outputs": [],
      "source": [
        "!ls drive/MyDrive/CorpusProfNer/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tGoyYbXwpzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iassJOc7wqEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TJN9dWCMwqHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_zIQ1TewqJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datapath='drive/MyDrive/CorpusProfner/'\n",
        "valid_file= datapath+'valid_clean.txt'\n",
        "\n",
        "training_file = datapath+'train_50_mr.txt'\n",
        "folder_name= \"test6\"\n"
      ],
      "metadata": {
        "id": "X3F3TdYJwqML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5kT0dCocgmU",
        "outputId": "8a6b5d2b-af97-4aa5-a987-b1acdc0144ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 15 20:15:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    52W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK5Hu9Qf2sbF"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttVqhVA-pf9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fac0352ce544489ab38fb152b35adf5f",
            "a4a46528927d416ea0cfe3cfd157eff8",
            "4223e1347f51414ba075717e8b133b7f",
            "18f1200eb4c941409f5c05775e451241",
            "be9d8c8d2dba411298c77425f94b978e",
            "c53aac19b5544f7db6ced160d19ddeec",
            "d49474168da74e9c808c5524bc8331df",
            "c135ab66b7834739be8ad086c21d13f3",
            "dab0d9d0bcc5427da51c378b03f7f259",
            "ac4501acfc0c4cc2ba16960019312299",
            "d0325a53a379414f92a8cfeb1faa793b",
            "4171364cd740482ca1ba88e1fb19f6ed",
            "275993b2bedb4ce8b66b98eab2ec7a51",
            "99ba0400c9dc4339b28c87a1913b567f",
            "a2b1541984ec4c659dcf3c9b8bedf362",
            "0ec2b8e4bc3d4f40a5037693743e6557",
            "c22524e0ef2f434e8d6f61fbe1fef2b1",
            "d7fb7e26931840f3a0ed86b69a777e45",
            "b4c5fe00c63f426c8faa9f65b36f2b45",
            "551f4f15d5cf4a7fbc933b7027a3200d",
            "2abf16742c544e61a7052b3c6a9df2e5",
            "526c117b97e14711b1dc450780abc66b"
          ]
        },
        "outputId": "2b2f4e84-52c8-45cf-823f-9ccfa25dec04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/merges.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fac0352ce544489ab38fb152b35adf5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4171364cd740482ca1ba88e1fb19f6ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"B-PROFESION\",\n",
            "    \"2\": \"I-PROFESION\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-PROFESION\": 1,\n",
            "    \"I-PROFESION\": 2,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/6f11dfab050340aebc487ccf58ce349b8f88bc67/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the training set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 11050\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4146\n",
            "  Number of trainable parameters = 124055043\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4146' max='4146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4146/4146 06:04, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.102200</td>\n",
              "      <td>0.025206</td>\n",
              "      <td>0.727869</td>\n",
              "      <td>0.644412</td>\n",
              "      <td>0.683603</td>\n",
              "      <td>0.993324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.012800</td>\n",
              "      <td>0.036358</td>\n",
              "      <td>0.691740</td>\n",
              "      <td>0.680697</td>\n",
              "      <td>0.686174</td>\n",
              "      <td>0.993109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.033699</td>\n",
              "      <td>0.709585</td>\n",
              "      <td>0.719884</td>\n",
              "      <td>0.714697</td>\n",
              "      <td>0.993756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.039101</td>\n",
              "      <td>0.756800</td>\n",
              "      <td>0.686502</td>\n",
              "      <td>0.719939</td>\n",
              "      <td>0.993921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.033996</td>\n",
              "      <td>0.752624</td>\n",
              "      <td>0.728592</td>\n",
              "      <td>0.740413</td>\n",
              "      <td>0.994327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.039626</td>\n",
              "      <td>0.716954</td>\n",
              "      <td>0.724238</td>\n",
              "      <td>0.720578</td>\n",
              "      <td>0.993629</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3693\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3693\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3693\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3693\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3693\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3693\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4146, training_loss=0.01540013221782141, metrics={'train_runtime': 364.5775, 'train_samples_per_second': 181.854, 'train_steps_per_second': 11.372, 'total_flos': 1942150613526576.0, 'train_loss': 0.01540013221782141, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from datasets import load_metric\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "def read_bio_dataset(dir):\n",
        "  tok = []  #Aux list of tokens for current sentence\n",
        "  bio = []  #Aux list of ner tags for current sentence\n",
        "  df_list = []  #Final list with all the information\n",
        "\n",
        "  with open(dir,'r',encoding='utf-8') as file:\n",
        "    for line in file.readlines():\n",
        "\n",
        "      #When reaching the end of a sentence, we append and restart tok and bio\n",
        "      #We also check for non-empty sentences\n",
        "      if line == '\\n' and tok!=[] and bio!=[]:\n",
        "        df_list.append([tok,bio])\n",
        "        tok = []\n",
        "        bio = []\n",
        "\n",
        "      else:\n",
        "\n",
        "        #We add the token and ner_tag to the list\n",
        "        tok.append(line.split(' ')[0])\n",
        "        bio.append(line.split(' ')[-1].replace('\\n',''))\n",
        "\n",
        "  #Returning df_list to a dataframe\n",
        "  return pd.DataFrame(df_list, columns=['tokens','ner_tags'])\n",
        "\n",
        "import emoji\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def read_tsv_dataset(name):\n",
        "  training_data= pd.read_csv(name, sep=\"\\t\",encoding='utf8')\n",
        "  training_data['tokens'] = training_data['tokens'].apply(eval)\n",
        "  training_data['ner_tags'] = training_data['ner_tags'].apply(eval)\n",
        "  return training_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "write_bio_dataset(valid_data,'valid_formated.txt')\n",
        "write_bio_dataset(training_data,'train_formated.txt')\n",
        "\n",
        "\n",
        "valid_data = read_bio_dataset('valid_spacy.txt')\n",
        "valid_data = clean_data(valid_data)\n",
        "valid_data.head(26)\n",
        "\n",
        "training_data = read_bio_dataset('train_spacy.txt')\n",
        "training_data = clean_data(training_data)\n",
        "training_data.head(26)\n",
        "\n",
        "\n",
        "valid_data = read_bio_dataset('valid_formated.txt')\n",
        "training_data = read_bio_dataset('train_formated.txt')\n",
        "\n",
        "valid_data = clean_data(valid_data)\n",
        "training_data = clean_data(training_data)\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "valid_data = read_bio_dataset(valid_file)\n",
        "\n",
        "training_data= read_bio_dataset(training_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "training_data= pd.read_csv('training_or.tsv', sep=\"\\t\", encoding='utf8')\n",
        "training_data['tokens'] = training_data['tokens'].apply(eval)\n",
        "training_data['ner_tags'] = training_data['ner_tags'].apply(eval)\n",
        "\n",
        "training_data = clean_data(training_data)\n",
        "training_data\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "train_dataset = Dataset.from_pandas(training_data)\n",
        "test_dataset = Dataset.from_pandas(valid_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "labels_list = ['O', 'B-PROFESION', 'I-PROFESION']\n",
        "label_num_list= list(range(0,len(labels_list)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "label2id={}\n",
        "id2label={}\n",
        "for label,num in zip(labels_list,label_num_list):\n",
        "  label2id[label]=num\n",
        "  id2label[num]=label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "task = \"ner\"\n",
        "\n",
        "model_checkpoint = \"PlanTL-GOB-ES/roberta-base-bne\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True, truncation=True,  max_length=512)\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    label_all_tokens = True\n",
        "    tokenized_inputs = tokenizer(list(examples[\"tokens\"]),  truncation=True, is_split_into_words=True)\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif label[word_idx] == 'O':\n",
        "                label_ids.append(0)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label2id[label[word_idx]])#(label2id[label[word_idx]])\n",
        "                #label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(label2id[label[word_idx]] if label_all_tokens else -100)#(label2id[label[word_idx]] if label_all_tokens else -100)\n",
        "                #label_ids.append(label[word_idx] if label_all_tokens else -100)#(label2id[label[word_idx]] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "\n",
        "train_tokenized_datasets = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "#valid_tokenized_datasets = valid_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "test_tokenized_datasets = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "\n",
        "\n",
        "from transformers import  RobertaForTokenClassification, AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(labels_list), id2label = id2label, label2id = label2id)\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "epochs= 6\n",
        "args = TrainingArguments(\n",
        "    folder_name,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=1e-4,\n",
        "    #fp16=True,\n",
        "    #\"weight_decay\": (0, 0.3),\n",
        "  #\"learning_rate\": (1e-5, 5e-5),\n",
        "\n",
        "\n",
        "\n",
        "    optim=\"adamw_torch\"\n",
        "\n",
        "   # report_to=\"wandb\" ## WANDB\n",
        "\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    #print(predictions)\n",
        "\n",
        "    true_predictions = [[labels_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
        "    true_labels = [[labels_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\"precision\": results[\"overall_precision\"], \"recall\": results[\"overall_recall\"], \"f1\": results[\"overall_f1\"], \"accuracy\": results[\"overall_accuracy\"]}\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_tokenized_datasets,\n",
        "    eval_dataset=test_tokenized_datasets,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jVN43OzjKELM",
        "outputId": "8cf63ce4-056e-4705-e836-fe167a616e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.25.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "datasets.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "avPNk0l1KgTe",
        "outputId": "69ddf582-4862-4b3a-9f7c-3f77da8ad465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.7.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "LLEIjJ4bLPrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_val()"
      ],
      "metadata": {
        "id": "9JrRvlg1xenf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI02CzT76zzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5855a0b-3e4d-43eb-a351-9b2fcd86912c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 11052\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized_datasets[0]"
      ],
      "metadata": {
        "id": "zv82Nexwyh5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_tokenizeddataset(train_tokenized_datasets,'train_full.txt')"
      ],
      "metadata": {
        "id": "RO955dSOzCKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_tokenizeddataset(dataset,outputfile):\n",
        "  with open(outputfile, 'w') as f:\n",
        "\n",
        "    for index in range(0,len(dataset)):\n",
        "      toks= dataset[index]['input_ids']\n",
        "      tags= dataset[index]['labels']\n",
        "      f.write(str(toks)+'\\n')\n",
        "      f.write(str(tags)+'\\n')\n",
        "      f.write('\\n')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZTjYipjoyzX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyLN6PYm67i1"
      },
      "source": [
        "#Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiEqS_c97H6V",
        "outputId": "bb8df867-d26f-4d07-bef3-65dbc4536750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwaBCrrzU-Pi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sfqg_hxkg940"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_tokenized_datasets,\n",
        "    eval_dataset=test_tokenized_datasets,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhNlmPWeTxtn"
      },
      "outputs": [],
      "source": [
        "!rm -r profner_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URDEgE7M4_Jx"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()\n",
        "trainer.save_model('profner1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdta2qrxb6VI"
      },
      "outputs": [],
      "source": [
        "!pip install numba\n",
        "\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkRVPR0d72MO"
      },
      "source": [
        "#Excuting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6IlozSq1yVn",
        "outputId": "b359ec8d-624e-4312-949f-ffed0d9a7a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Building wheel for pyocclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyocclient -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo9EmjIH73tG"
      },
      "outputs": [],
      "source": [
        "import owncloud\n",
        "oc = owncloud.Client('https://delicias.dia.fi.upm.es/nextcloud/')\n",
        "#oc.login('asanchez', 'AS.sczz.448')\n",
        "oc.login('pcalleja', 'oWn.ser.5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdFGk-Bt8BGv"
      },
      "outputs": [],
      "source": [
        "!zip -r ./base.model-5.zip ./base.model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOvw2Hc076hF"
      },
      "outputs": [],
      "source": [
        "oc.put_file('base-model-5.zip', 'base.model-5.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnu1hi-ZVtHK"
      },
      "outputs": [],
      "source": [
        "oc.get_file('ProfNer/training_or.tsv', 'training_or.tsv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oc.get_file('ProfNer/training_50.tsv', 'training_50.tsv')\n",
        "oc.get_file('ProfNer/training_30.tsv', 'training_30.tsv')\n",
        "oc.get_file('ProfNer/training_10.tsv', 'training_10.tsv')\n",
        "oc.get_file('ProfNer/train_spacy.txt', 'train_spacy.txt')\n",
        "oc.get_file('ProfNer/valid_spacy.txt', 'valid_spacy.txt')"
      ],
      "metadata": {
        "id": "lMxn0P_z0aGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl_4QgH2VtQe"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"profner1\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"profner1\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yMsf-mT6wbV",
        "outputId": "b7a06830-7d41-4787-c964-5896d7982f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "example = \"hola conductores de ambulancia y viva la guardia civil\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXn2vwtaV_Ih"
      },
      "outputs": [],
      "source": [
        "nlp('Regarding Mossack Fonseca S.A.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZkRVPR0d72MO"
      ],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fac0352ce544489ab38fb152b35adf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4a46528927d416ea0cfe3cfd157eff8",
              "IPY_MODEL_4223e1347f51414ba075717e8b133b7f",
              "IPY_MODEL_18f1200eb4c941409f5c05775e451241"
            ],
            "layout": "IPY_MODEL_be9d8c8d2dba411298c77425f94b978e"
          }
        },
        "a4a46528927d416ea0cfe3cfd157eff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53aac19b5544f7db6ced160d19ddeec",
            "placeholder": "​",
            "style": "IPY_MODEL_d49474168da74e9c808c5524bc8331df",
            "value": "100%"
          }
        },
        "4223e1347f51414ba075717e8b133b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c135ab66b7834739be8ad086c21d13f3",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dab0d9d0bcc5427da51c378b03f7f259",
            "value": 12
          }
        },
        "18f1200eb4c941409f5c05775e451241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4501acfc0c4cc2ba16960019312299",
            "placeholder": "​",
            "style": "IPY_MODEL_d0325a53a379414f92a8cfeb1faa793b",
            "value": " 12/12 [00:01&lt;00:00,  8.22ba/s]"
          }
        },
        "be9d8c8d2dba411298c77425f94b978e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c53aac19b5544f7db6ced160d19ddeec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49474168da74e9c808c5524bc8331df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c135ab66b7834739be8ad086c21d13f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab0d9d0bcc5427da51c378b03f7f259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac4501acfc0c4cc2ba16960019312299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0325a53a379414f92a8cfeb1faa793b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4171364cd740482ca1ba88e1fb19f6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_275993b2bedb4ce8b66b98eab2ec7a51",
              "IPY_MODEL_99ba0400c9dc4339b28c87a1913b567f",
              "IPY_MODEL_a2b1541984ec4c659dcf3c9b8bedf362"
            ],
            "layout": "IPY_MODEL_0ec2b8e4bc3d4f40a5037693743e6557"
          }
        },
        "275993b2bedb4ce8b66b98eab2ec7a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c22524e0ef2f434e8d6f61fbe1fef2b1",
            "placeholder": "​",
            "style": "IPY_MODEL_d7fb7e26931840f3a0ed86b69a777e45",
            "value": "100%"
          }
        },
        "99ba0400c9dc4339b28c87a1913b567f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4c5fe00c63f426c8faa9f65b36f2b45",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_551f4f15d5cf4a7fbc933b7027a3200d",
            "value": 4
          }
        },
        "a2b1541984ec4c659dcf3c9b8bedf362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2abf16742c544e61a7052b3c6a9df2e5",
            "placeholder": "​",
            "style": "IPY_MODEL_526c117b97e14711b1dc450780abc66b",
            "value": " 4/4 [00:00&lt;00:00, 13.10ba/s]"
          }
        },
        "0ec2b8e4bc3d4f40a5037693743e6557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22524e0ef2f434e8d6f61fbe1fef2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fb7e26931840f3a0ed86b69a777e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4c5fe00c63f426c8faa9f65b36f2b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551f4f15d5cf4a7fbc933b7027a3200d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2abf16742c544e61a7052b3c6a9df2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526c117b97e14711b1dc450780abc66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}